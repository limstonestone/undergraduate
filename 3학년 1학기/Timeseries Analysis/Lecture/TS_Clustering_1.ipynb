{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONq4JsYruoZy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os, time, re\n",
        "import pickle, gzip, datetime\n",
        "from os import listdir, walk\n",
        "from os.path import isfile, join"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6uVnvsGvKFD"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "color = sns.color_palette()\n",
        "import matplotlib as mpl\n",
        "from mpl_toolkits.axes_grid1 import Grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qx91zJMCvTbJ"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JoP8EE6rvWN-"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing as pp\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.model_selection import StratifiedKFold \n",
        "from sklearn.metrics import log_loss, accuracy_score\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score, mean_squared_error\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import adjusted_rand_score\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PuAY6ZwwSMx"
      },
      "outputs": [],
      "source": [
        "!pip install kshape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxSj_gcmwidi"
      },
      "outputs": [],
      "source": [
        "!pip install tslearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1C-9-khsxo4X"
      },
      "outputs": [],
      "source": [
        "!pip install hdbscan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljdXqfvZvaGW"
      },
      "outputs": [],
      "source": [
        "from kshape.core import kshape, zscore\n",
        "import tslearn\n",
        "from tslearn.utils import to_time_series_dataset\n",
        "from tslearn.clustering import KShape\n",
        "from tslearn.preprocessing import TimeSeriesScalerMeanVariance\n",
        "from tslearn.clustering import TimeSeriesKMeans\n",
        "import hdbscan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYKcjS1iwEsN"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Activation, Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
        "from keras.layers import LeakyReLU, Reshape, UpSampling2D, Conv2DTranspose\n",
        "from keras.layers import BatchNormalization, Input, Lambda\n",
        "from keras.layers import Embedding, Flatten, dot\n",
        "from keras import regularizers\n",
        "from keras.losses import mse, binary_crossentropy\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xb8pRn1632_o"
      },
      "outputs": [],
      "source": [
        "## 로딩한 압축파일 풀기\n",
        "!unzip -qq \"/content/ECG5000.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44P0zLiL0MIO"
      },
      "outputs": [],
      "source": [
        "## 데이터 로드\n",
        "# ECG5000 데이터셋에 대한 설명: https://timeseriesclassification.com/description.php?Dataset=ECG5000\n",
        "data_train = np.loadtxt(\"ECG5000_TRAIN.txt\")\n",
        "data_test = np.loadtxt(\"ECG5000_TEST.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0iFVI_Po7lZM"
      },
      "outputs": [],
      "source": [
        "## 요약통계량 확인하기\n",
        "print(\"Number of time series:\", len(data_train))\n",
        "print(\"Number of unique classes:\", len(np.unique(data_train[:,0])))\n",
        "print(\"Time series length:\", len(data_train[0,1:]))\n",
        "\n",
        "print(\"Number of time series:\", len(data_test))\n",
        "print(\"Number of unique classes:\", len(np.unique(data_test[:,0])))\n",
        "print(\"Time series length:\", len(data_test[0,1:]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ImfYvFl37qVz"
      },
      "outputs": [],
      "source": [
        "## 클래스 별 샘플 수 확인\n",
        "print(\"Number of time series in class 1.0:\", \n",
        "      len(data_train[data_train[:,0]==1.0]))\n",
        "print(\"Number of time series in class 2.0:\", \n",
        "      len(data_train[data_train[:,0]==2.0]))\n",
        "print(\"Number of time series in class 3.0:\", \n",
        "      len(data_train[data_train[:,0]==3.0]))\n",
        "print(\"Number of time series in class 4.0:\", \n",
        "      len(data_train[data_train[:,0]==4.0]))\n",
        "print(\"Number of time series in class 5.0:\", \n",
        "      len(data_train[data_train[:,0]==5.0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gR3_B0437uRD"
      },
      "outputs": [],
      "source": [
        "## 각 클래스 별 수치값 보기\n",
        "for j in np.unique(data_train[:,0]):\n",
        "    dataPlot = data_train[data_train[:,0]==j]\n",
        "    cnt = len(dataPlot)\n",
        "    dataPlot = dataPlot[:,1:].mean(axis=0)\n",
        "    print(\" Class \",j,\" Count \",cnt)\n",
        "    plt.plot(dataPlot)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ECG5000 training 데이터셋과 test 데이터셋을 병합한 후, 다시 training 데이터셋과 test 데이터셋으로 나누기 \n",
        "data_joined = np.concatenate((data_train,data_test),axis=0)\n",
        "data_train, data_test = train_test_split(data_joined, \n",
        "                                    test_size=0.20, random_state=2019)\n",
        "\n",
        "X_train = to_time_series_dataset(data_train[:, 1:])\n",
        "y_train = data_train[:, 0].astype(np.int)\n",
        "X_test = to_time_series_dataset(data_test[:, 1:])\n",
        "y_test = data_test[:, 0].astype(np.int)"
      ],
      "metadata": {
        "id": "7JgU-NTY3pJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 요약통계량 확인하기\n",
        "print(\"Number of time series:\", len(data_train))\n",
        "print(\"Number of unique classes:\", len(np.unique(data_train[:,0])))\n",
        "print(\"Time series length:\", len(data_train[0,1:]))\n",
        "\n",
        "print(\"Number of time series:\", len(data_test))\n",
        "print(\"Number of unique classes:\", len(np.unique(data_test[:,0])))\n",
        "print(\"Time series length:\", len(data_test[0,1:]))"
      ],
      "metadata": {
        "id": "dlPhFiEg32W6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 클래스 별 샘플 수 확인\n",
        "print(\"Number of time series in class 1.0:\", \n",
        "      len(data_train[data_train[:,0]==1.0]))\n",
        "print(\"Number of time series in class 2.0:\", \n",
        "      len(data_train[data_train[:,0]==2.0]))\n",
        "print(\"Number of time series in class 3.0:\", \n",
        "      len(data_train[data_train[:,0]==3.0]))\n",
        "print(\"Number of time series in class 4.0:\", \n",
        "      len(data_train[data_train[:,0]==4.0]))\n",
        "print(\"Number of time series in class 5.0:\", \n",
        "      len(data_train[data_train[:,0]==5.0]))"
      ],
      "metadata": {
        "id": "j1qLSRXR4BHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 각 클래스 별 수치값 보기\n",
        "for j in np.unique(data_train[:,0]):\n",
        "    dataPlot = data_train[data_train[:,0]==j]\n",
        "    cnt = len(dataPlot)\n",
        "    dataPlot = dataPlot[:,1:].mean(axis=0)\n",
        "    print(\" Class \",j,\" Count \",cnt)\n",
        "    plt.plot(dataPlot)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "3ic9W8FC4IUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLBB2pod71d7"
      },
      "outputs": [],
      "source": [
        "## 데이터 정규화\n",
        "X_train = TimeSeriesScalerMeanVariance(mu=0., std=1.).fit_transform(X_train)\n",
        "X_test = TimeSeriesScalerMeanVariance(mu=0., std=1.).fit_transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00GOdpwrG4x-"
      },
      "outputs": [],
      "source": [
        "### k-shape\n",
        "## https://tslearn.readthedocs.io/en/stable/gen_modules/clustering/tslearn.clustering.KShape.html\n",
        "## 논문: http://www1.cs.columbia.edu/~jopa/Papers/PaparrizosSIGMOD2015.pdf\n",
        "## 논문: http://web5.cs.columbia.edu/~gravano/Papers/2017/tods17.pdf\n",
        "## 논문: https://fluidsbarrierscns.biomedcentral.com/track/pdf/10.1186/s12987-022-00311-5.pdf\n",
        "## https://techy8855.tistory.com/m/21\n",
        "## 성능평가측도: 수정된 Rand 지수 - 우연히 그룹회된 성분에 대해 조정된 두 데이터 군집 간 유사성 측도\n",
        "# 예측군집과 실제 군집 사이의 군집 할당에서 일치하는 개수를 측정한다.\n",
        "# 0에 가까운 경우 순전히 무작위로 군집을 할당한 것\n",
        "# 1에 가까울 경우 예측군집과 실제군집이 정확하게 일치하는 것 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkPjQeVC77VL"
      },
      "outputs": [],
      "source": [
        "## k-shape를 사용한 훈련\n",
        "ks = KShape(n_clusters=5, max_iter=100, n_init=10,verbose=1,random_state=2019)\n",
        "ks.fit(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPw6sBjD78DY"
      },
      "outputs": [],
      "source": [
        "## 훈련 데이터에 대한 예측값 생성 및 수정된 Rand 지수 계산\n",
        "preds = ks.predict(X_train)\n",
        "ars = adjusted_rand_score(data_train[:,0],preds)\n",
        "print(\"Adjusted Rand Index on Training Set:\", ars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69ZxexIr8FJC"
      },
      "outputs": [],
      "source": [
        "## 테스트 데이터에 대한 예측값 생성 및 수정된 Rand 지수 계산\n",
        "preds = ks.predict(X_train)\n",
        "preds_test = ks.predict(X_test)\n",
        "ars = adjusted_rand_score(data_test[:,0],preds_test)\n",
        "print(\"Adjusted Rand Index on Test Set:\", ars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdAHyhdn8GKY"
      },
      "outputs": [],
      "source": [
        "## 군집별 적합도 검정\n",
        "preds_test = preds_test.reshape(1000,1)\n",
        "preds_test = np.hstack((preds_test,data_test[:,0].reshape(1000,1)))\n",
        "preds_test = pd.DataFrame(data=preds_test)\n",
        "preds_test = preds_test.rename(columns={0: 'prediction', 1: 'actual'})\n",
        "\n",
        "counter = 0\n",
        "for i in np.sort(preds_test.prediction.unique()):\n",
        "    print(\"Predicted Cluster \", i)\n",
        "    print(preds_test.actual[preds_test.prediction==i].value_counts())\n",
        "    print()\n",
        "    cnt = preds_test.actual[preds_test.prediction==i].value_counts().iloc[1:].sum()\n",
        "    counter = counter + cnt\n",
        "print(\"Count of Non-Primary Points: \", counter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxHlw55I8JmX"
      },
      "outputs": [],
      "source": [
        "## 시계열 k-평균을 사용한 훈련\n",
        "# https://tslearn.readthedocs.io/en/stable/gen_modules/clustering/tslearn.clustering.TimeSeriesKMeans.html\n",
        "# TimeSeriesKMeans: metric={\"euclidean\", \"dtw\", \"softdtw\"}, default는 euclidean\n",
        "\n",
        "km = TimeSeriesKMeans(n_clusters=5, max_iter=100, n_init=100, metric=\"dtw\", verbose=1, random_state=2019)  \n",
        "km.fit(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksMNHGTw85nH"
      },
      "outputs": [],
      "source": [
        "# 훈련 셋에 대한 예측값 생성 및 수정된 Rand 지수를 사용한 평가\n",
        "preds = km.predict(X_train)\n",
        "ars = adjusted_rand_score(data_train[:,0],preds)\n",
        "print(\"Adjusted Rand Index of Time Series k-Means on Training Set:\", ars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpWUhLXE_N8X"
      },
      "outputs": [],
      "source": [
        "# 테스트 셋에 대한 예측값 생성 및 수정된 Rand 지수를 사용한 평가\n",
        "preds_test = km.predict(X_test)\n",
        "ars = adjusted_rand_score(data_test[:,0],preds_test)\n",
        "print(\"Adjusted Rand Index of Time Series k-Means on Test Set:\", ars)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "TS_Clustering-1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}