## classification error rate : 0.08333333
# Examples of Support Vector Machine
library(ALL)
data(ALL)
ALLB123 = ALL[, ALL$BT %in% c("B1", "B2", "B3")]
names = featureNames(ALL)
ALLBTnames = ALLB123[names, ]
probData = as.matrix(ecprs(ALLBTnames))
probData = as.matrix(exprs(ALLBTnames))
fun = function(x) anova(lm(x ~ ALLB123$BT))$Pr[1]
anova.pValue = apply(exprs(ALLB123), 1, fun)
ww = anova.pValue < 0.00001
diagnosed = factor(ALLBTnames$BT)
Data = data.frame(t(probeData[ww, ]), y=diagnosed)
probeData = as.matrix(exprs(ALLBTnames))
Data = data.frame(t(probeData[ww, ]), y=diagnosed)
set.seed(123)
train = sample(1:78, 39, replace=FALSE)
test = setdiff(1:78, train)
install.packages("e1071")
## install.packages("e1071")
library(e1071)
svmfit = svm(y ~., data=Data[train, ], kernel="linear")
summary(svmfit)
dim(Data)
pred.tr = predict(svmfit, Data[train, ])
table(pred.tr, Data[train, "y"])
pred.te = predict(svmfit, Data[test, ])
table(pred.te, Data[test, "y"])
mean(pred.te != Data[test, "y"])
fit1 = svm(y ~., data=Data[train, ], cost=0.001, kernel="linear")
fit2 = svm(y ~., data=Data[train, ], cost=0.01, kernel="linear")
fit3 = svm(y ~., data=Data[train, ], cost=0.1, kernel="linear")
fit4 = svm(y ~., data=Data[train, ], cost=10, kernel="linear")
pred.te = predict(fit1, Data[test, ])
table(pred.te, Data[test, "y"])
mean(pred.te != Data[test, "y"])
pred.te = predict(fit2, Data[test, ])
table(pred.te, Data[test, "y"])
mean(pred.te != Data[test, "y"])
pred.te = predict(fit3, Data[test, ])
table(pred.te, Data[test, "y"])
mean(pred.te != Data[test, "y"])
pred.te = predict(fit4, Data[test, ])
table(pred.te, Data[test, "y"])
mean(pred.te != Data[test, "y"])
set.seed(123)
tune.out = tune(svm, y ~., data=Data[train, ],
kernel="linear", ranges=list(cost=c(0.001, 0.01, 0.1, 1, 5, 10,1 00)))
tune.out = tune(svm, y ~., data=Data[train, ],
kernel="linear", ranges=list(cost=c(0.001, 0.01, 0.1, 1, 5, 10, 100)))
summary(tune.out)
tune.out$best.model
pred = predict(tune.out$best.model, Data[test, ])
table(pred, Data[test, "y"])
mean(pred != Data[test, "y"])
set.seed(12)
tout = tune(svm, y~., data=Data[train, ], kernel="polynomial",
ranges=list(cost=c(0.1,1,10,100), degree=c(2,3,4)))
pred = predict(tout$best.model, Data[test, ])
table(pred, Data[test, "y"])
tout = tune(svm, y~., data=Data[train, ], kernel="radial",
ranges=list(cost=c(0.1,1,10,100), gamma=c(0.5,1,2,3)))
pred = predict(tout$best.model, Data[test, ])
table(pred, Data[test, "y"])
mean(pred != Data[test, "y"])
tout = tune(svm, y~., data=Data[train, ], kernel="sigmoid",
ranges=list(cost=c(0.1,1,10,100), gamma=c(0.5,1,2,3)))
pred = predict(tout$best.model, Data[test, ])
table(pred, Data[test, "y"])
mean(pred != Data[test, "y"])
# Install Packages from Bioconductor
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install()
BiocManager::install("ALL")
library(ALL)
# golub Data Example
BiocManager::install("multtest")
install.packages("genetics")
install.packages("car")
install.packages("ape")
install.pakcages("nortest")
install.packages("nortest")
install.packages("outliers")
install.packages("ISLR2")
install.packages("qqman")
install.packages("RColorBrewer")
install.packages("lmtest")
BiocManager::install("ALL")
library(lmtest)
library(ISLR)
BiocManager::install("genefilter")
library(genefilter)
install.packages("gplots")
install.packages("ROCR")
install.packages(c("rpart", "rpart.plot"))
BiocManager::install("hgu95av2.db")
install.packages("randomForest")
install.packages("e1071")
##### <Lecture03 : Multiple Testing Procedure> #####
# Bonferroni Adjustment
## Bonferroni Adjustment는 대용량 데이터에서 FWER이 매우 커지는 문제를 방지하기 위해서 고안된 아이디어
data(golub, package="multtest")
golubFactor = factor(golub.cl, levels=0:1, labels=c("ALL", "AML"))
pval = NULL
m = nrow(golub)
ㅡ
m
dim(golub)
for (i in 1:m){
pval[i] = t.test(golub[i, ] ~ golubFactor)$p.val
}
pval
sum(pval < 0.05)    # Type 1 Error 가능성 다수 존재
sum(pval < 0.05/m)  # Type 1 Error 가능성 control
m
103/3051
1078/3051
top = 20
oo = order(pval)
oot = oo[1:top]
data.frame(gene=golub.gnames[oot, 3], pvalue=pval[oot])
order(pval)
order(pval)
order([1:20])
order(pval)[1:20]
oo
oo[1:top]
pj = p.adjust(pval, method="bonferroni")  # Bonferroni adjustment p-value
sum(pj < 0.05)  # = sum(pval < 0.05/m)
top = sum(pj < 0.05)
oo = order(pval)
oot = oo[1:top]
data.frame(gene=golub.gnames[oot, 3], pvalue=pval[oot], adj.pvalue=pj[oot])
par(mfrow=c(1, 2))
hist(pval, col="orange", xlab="", main="Un-adjusted p-values")
hist(pj, col="purple", xlab="", main="Adjusted p-values")
par(mfrow=c(1, 1))
plot(-log10(pval), type="p", pch=20, col="red", xlab="gene")
abline(h=-log10(0.05/m), lty=2) # 스케일링을 통해 Type 1 error 가능성 확인 (검은선 위로 Reject)
ph = p.adjust(pval, method="holm")
sum(ph < 0.05)
top = sum(ph < 0.05)
oo = order(pval)
oot = oo[1:top]
data.frame(gene=golub.gnames[oot, 3], pvalue=pval[oot],
Bonferroni=pj[oot], Holm=ph[oot])
pval2 = NULL
for (i in 1:m){
pval2[i] = wilcox.test(golub[i, ] ~ golubFactor)$p.val
}
# Benjamini-Hochberg procedure
## Method to conntrol FDR
## Error를 컨트롤하는 것 보다는 Siginificant discovery에 집중!
## 굉장히 Classic 하며 한계가 조금은 존재하는 method, 하지만 이해하기에는 쉬움
data(golub, package="multtest")
golubFactor = factor(golub.cl, levels=0:1, labels=c("ALL", "AML"))
pval = NULL
m = nrow(golub)
for (i in 1:m){
pval[i] = t.test(golub[i, ] ~ golubFactor)$p.val
}
pj = p.adjust(pval, method="bonferroni")
pBH = p.adjust(pval, method="BH")		# Benjamini-Hochberg
c(sum(pj < 0.05), sum(pBH < 0.05))	# more reject H0
q = 0.05
poo = sort(pval)
wh = which(poo < q*(1:m)/m)
whh = 1:max(wh)
plot(poo, pch=20, ylab="P-values", xlab="Genes", main="")
points(whh, poo[whh], col=4, pch=20)
abline(a=0, b=q/m, col=2)
abline(h=q/m, col="darkgreen")
plot(poot, pch=20, ylab="P-values", xlab="Genes", main="")
top = 1000
plot(poo, pch=20, ylab="P-values", xlab="Genes", main="")
points(whh, poo[whh], col=4, pch=20)
abline(a=0, b=q/m, col=2)
q/m
abline(h=q/m, col="darkgreen")
top = 1000
poot = poo[1:top]
plot(poot, pch=20, ylab="P-values", xlab="Genes", main="")
points(whh, poot[whh], col=4, pch=20)
abline(a=0, b=q/m, col=2)
abline(h=q/m, col="darkgreen")
plot(poo, pch=20, ylab="P-values", xlab="Genes", main="")
poo
# Permutation to Compute p-value
## install.packages("ISLR2")
library(ISLR2)
data(Khan)
?Khan
str(Khan)
x = rbind(xtrain, xtest)
# Permutation to Compute p-value
## install.packages("ISLR2")
library(ISLR2)
data(Khan)
?Khan
str(Khan)
attach(Khan)
x = rbind(xtrain, xtest)
y = c(as.numeric(ytrain), as.numeric(ytest))
dim(x)
table(y)
x = rbind(xtrain, xtest)
y = c(as.numeric(ytrain), as.numeric(ytest))
dim(x)
table(y)
y
x
y
length(y)
x = as.matrix(x)
x1 = x[which(y==2), ]	# target=2인 데이터로만
x2 = x[which(y==4), ]	# target=4인 데이터로만
n1 = nrow(x1)
n2 = nrow(x2)
k = 11 # 11번째 gene에 대해서 검정
shapiro.test(x1[, k])	# not reject H0 -> 정규성을 따른다 -> t.test 가능
shapiro.test(x2[, k])	# not reject H0
t.out = t.test(x1[, k], x2[, k], var.equal=TRUE)
t.out$statistic
t.out$p.value	# reject H0 -> 두 집단간의 차이가 존재한다 (p-value가 아슬아슬하긴 함 = 차이가 있지만 크진 않을수도?)
set.seed(1)
B = 10000
T = rep(NA, B)
t = sample(c(x1[, k], x2[,k]))
dim(t)
length(t)
t = sample(c(x1[, k], x2[,k]))
length(t)
t
for (j in 1:B) {	# permutation test
data = sample(c(x1[, k], x2[, k]))
T[j] = t.test(data[1:n1], data[(n1 + 1) : (n1 + n2)],
var.eqaul=TRUE)$statistic
}
hist(T, breaks=100, xlim=c(-4.2, 4.2), main="", xlab="Null Distribution of Test Statistics", col=7)	# under H0에서의 t분포 시각화
x0 = seq(-4.2, 4.2, len=1000)
y0 = dt(seq(-4.2, 4.2, len=1000), df=(n1+n2-2))
lines(x0, y0*1000, col=2, lwd=3)
TT = t.out$statistic
abline(v=-TT, col=4, lty=2, lwd=2)
abline(v=TT, col=4, lty=2, lwd=2)
text(TT-1, 350, paste("T = ", round(TT, 4), sep=""), col=4)
k = 877
shapiro.test(x1[, k])	# reject H0 -> 정규성 위반 -> t-test 하면 안됨!
shapiro.test(x2[, k])	# reject H0
x1[,k]
shapiro.test(x1[, k])	# reject H0 -> 정규성 위반 -> t-test 하면 안됨!
shapiro.test(x2[, k])	# reject H0
par(mfrow=c(1, 2))
qqnorm(x1[, k], pch=19, col='red', main=expression(x[1]))	# Q-Q plot
qqline(x1[, k])
qqnorm(x2[, k], pch=19, col='red', main=expression(x[2]))
qqline(x2[, k])
T = rep(NA, B)
T = rep(NA, B)
set.seed(2)
for (j in 1:B) {
dat = sample(c(x1[, k], x2[, k]))
T[j] = t.test(dat[1:n1], dat[(n1 + 1):(n1 + n2)],
var.equal=TRUE)$statistic
}
t.out = t.test(x1[, k], x2[, k], var.equal=TRUE)
t.out$p.value	# 정규성 만족하지 않으므로 좋지 않음
hist(T, breaks=100, xlim=c(-2.9, 2.9), main="", xlab="Null Distribution of Test Statistic", col=7)	# bimodel(봉우리 두개 형태)
x0 = seq(-2.9, 2.9, len=1000)
y0 = dt(seq(-2.9, 2.9, len=1000), df=(n1 + n2 -2))
lines(x0, y0*1000, col=2, lwd=3)
TT = t.out$statistic
abline(v=-TT, col=4, lty=2, lwd=2)
abline(v=TT, col=4, lty=2, lwd=2)
text(TT-1, 200, paste("T = ", round(TT, 4), sep=""), col=4)
par(mfrow=c(1,1))
hist(T, breaks=100, xlim=c(-2.9, 2.9), main="", xlab="Null Distribution of Test Statistic", col=7)	# bimodel(봉우리 두개 형태)
x0 = seq(-2.9, 2.9, len=1000)
y0 = dt(seq(-2.9, 2.9, len=1000), df=(n1 + n2 -2))
lines(x0, y0*1000, col=2, lwd=3)
lines(x0, y0*100, col=2, lwd=3)
par(mfrow=c(1,1))
hist(T, breaks=100, xlim=c(-2.9, 2.9), main="", xlab="Null Distribution of Test Statistic", col=7)	# bimodel(봉우리 두개 형태)
x0 = seq(-2.9, 2.9, len=1000)
y0 = dt(seq(-2.9, 2.9, len=1000), df=(n1 + n2 -2))
lines(x0, y0*500, col=2, lwd=3)
TT = t.out$statistic
abline(v=-TT, col=4, lty=2, lwd=2)
abline(v=TT, col=4, lty=2, lwd=2)
text(TT-1, 200, paste("T = ", round(TT, 4), sep=""), col=4)
# Computation of Plug-in FDR
m = 200
B = 1000	# 시간관계상 1000번이지, 실제로는 매우 적은 횟수
set.seed(111)
index = sample(2308, m)
T = rep(NA, m)
T.star = matrix(NA, nrow=m, ncol=B)
for (j in 1:m){
k = index[j]
T[j] = t.test(x1[, k], x2[, k], var.equal=TRUE)$statistic
for (b in 1:B) {
dat = sample(c(x1[, k], x2[, k]))
T.star[j, b] = t.test(dat[1:n1], dat[(n1 + n1) : (n1 + n2)], var.equal=TRUE)$statistic
}
}
c = sort(abs(T))
FDR = R = V = rep(NA, m)
for (j in 1:m){
R[j] = sum(abs(T) >= c[j])
V[j] = sum(abs(T.star) >= c[j])/B
FDR[j] = V[j]/R[j]
}
plot(R, FDR, xlab="Number of Rejections", type="l", ylab="False Discovery Rate", col=4, lwd=3)
oo = order(abs(T))
R[oo] = R		# ordering을 하지 않으면 index가 뒤죽박죽
FDR[oo] = FDR
alpha = 0.1
max(R[FDR <= alpha])
sort(index[FDR <= alpha])
pval = NULL
for (j in 1:m){
k = index[j]
pval[j] = t.test(x1[, k], x2[, k], var.equal=TRUE)$p.value
}
# Computation of Plug-in FDR
m = 200
B = 1000	# 시간관계상 1000번이지, 실제로는 매우 적은 횟수
set.seed(111)
index = sample(2308, m)
T = rep(NA, m)
T.star = matrix(NA, nrow=m, ncol=B)
for (j in 1:m){
k = index[j]
T[j] = t.test(x1[, k], x2[, k], var.equal=TRUE)$statistic
for (b in 1:B) {
dat = sample(c(x1[, k], x2[, k]))
T.star[j, b] = t.test(dat[1:n1], dat[(n1 + n1) : (n1 + n2)], var.equal=TRUE)$statistic
}
}
c = sort(abs(T))
FDR = R = V = rep(NA, m)
for (j in 1:m){
R[j] = sum(abs(T) >= c[j])
V[j] = sum(abs(T.star) >= c[j])/B
FDR[j] = V[j]/R[j]
}
plot(R, FDR, xlab="Number of Rejections", type="l", ylab="False Discovery Rate", col=4, lwd=3)
oo = order(abs(T))
R[oo] = R		# ordering을 하지 않으면 index가 뒤죽박죽
FDR[oo] = FDR
alpha = 0.1
max(R[FDR <= alpha])
sort(index[FDR <= alpha])
pval = NULL
for (j in 1:m){
k = index[j]
pval[j] = t.test(x1[, k], x2[, k], var.equal=TRUE)$p.value
}
pBH = p.adjust(pval, method="BH")
data.frame(Resampling=round(FDR ,6), BH=round(pBH, 6))	# Resampling과 Benjamini procedure의 값이 거의 비슷함을 알 수 있음
oo = order(pBH)
plot(FDR[oo], pBH[oo], pch=20, xlab="Reampling FDR", ylab="BH procedure")
abline(0, 1, col="red", lty=2)	# 시각화 결과 y=x선상에 거의 겹침, 즉 값이 거의 일치
R
T.star
dim(T.star)
c
dim(sort)
dim(c)
legnth(c)
length(c)
abs(T.star)
# Least Square Estimation
data(golub, package="multtest")
zyxin = grep("Zyxin", golub.gnames[,2], ignore.case=TRUE)
cmyb = grep("c-myb", golub.gnames[,2], ignore.case=TRUE)
x = golub[zyxin, ]
y = golub[cmyb, ]
leastSquares = lm(y ~ x)
leastSquares$coef
plot(x, y, pch=19, xlab="Relative zyxin gene expression", ylab="Relative c-MYB gene expression", cex.lab=1.5, col="blue")
abline(leastSquares$coef, lwd=3, lty=2, col="red")
lmSummary = summary(leastSquares)
lmSummary
dim(x)
length(x)
# Linear Model with a Factor
y = c(2, 3, 1, 2, 8, 7, 9, 8, 11, 12, 13, 12)
factor = gl(3, 4) # gl : Generate factors by specifying the pattern of their levels.
factor
model.matrix(y ~ factor - 1)  # model.matrix = design matrix X, -1 indicates model has no intercept
summary(lm(y ~ factor -1))  # p-values are too small -> Reject H0 (mu_j = 0)
length(y)
summary(lm(y ~ factor -1))  # p-values are too small -> Reject H0 (mu_j = 0)
# Linear Model in ANOVA
set.seed(123)
y = c(rnorm(10, -1, 1), rnorm(10, 0, 1), rnorm(10, 1, 1))
y
factor = gl(3, 10)
factor
model.matrix(y ~ factor -1)
model.matrix(y ~ factor)  # Reference : factor1
g1 = lm(y ~ factor -1)
g2 = lm(y ~ factor)
summary(g1)$coef  # we can see mean of reference equals to estimates of intercept
summary(g2)$coef
anova(g1) # Wrong result (because of df=3)
anova(g2)
y = c(2, 3, 1, 2, 8, 7, 9, 8, 11, 12, 13, 12)
factor = gl(3, 4)
groupMeans = as.numeric(tapply(y, factor, mean))  # tapply : perform function about factor
groupMeans
mean(y)
g = 3
n = 4
N = 12
g = 3
n = 4
N = 12
ssb = 0
for (j in 1:g) {
ssb = ssb + (groupMeans[j] - mean(y))^2
}
SSB = n * ssb
SSB
SSW = 0
for (j in 1:g) {
SSW = SSW + sum((y[factor==j] - groupMeans[j])^2)
}
f.value = (SSB/(g-1)) / (SSW/(N-g))
f.value
pf(f.value, g-1, N-g, lower.tail=FALSE) # lower.tail : calculate only tail
g = lm(y ~ factor)
anova(g)
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("golubEsets")
library(golubEsets)
library(rpart)
library(e1071)
source("~/.active-rstudio-document", echo=TRUE)
install.packages("rpart")
install.packages("e1071")
data(golubEsest)
data(golubMerge)
data = data(golubMerge)
data
list(data)
dim(data)
data
data = data(Golub_Merge)
data
dim(data)
data(golubMerge)
data(Golub_Merge)
data
data = data(Golub_Merge)
data
x = data(Golub_Merge)
x
data(golubTest)
BiocManager::install("golubEsets")
x = data(Golub_Merge)
x
x = data(Golub_Merge)$Golub_Merge
library(golubEsets)
x = data(Golub_Merge)
x
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("golubEsets")
library(golubEsets)
library(rpart)
library(e1071)
x = data(Golub_Merge)
x
library(SubLasso)
install.packages("golubEsets")
install.packages("golubEsets")
library(golubEsets)
x = data(Golub_Merge)
x
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("golubEsets")
library(golubEsets)
data("Golub_Merge")
x = data("Golub_Merge")
x
data(Golub_Merge)
rm(list=ls())
data(Golub_Merge)
View(Golub_Merge)
Golub_Merge$ALL.AML
exprs(Golub_Merge)
data = exprs(Golub_Merge)
data
dim(data)
colnames(data)
golub$ALL.AML
Golub_Merge$ALL.AML
fac = Golub_Merge$ALL.AML
fac
Golub_Merge
exprs(Golub_Merge)
data
colnames(data)
fac
str(Golub_Merge)
golub.cl
