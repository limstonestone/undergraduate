}
}
c = sort(abs(T))
FDR = R = V = rep(NA, m)
for (j in 1:m){
R[j] = sum(abs(T) >= c[j])
V[j] = sum(abs(T.star) >= c[j])/B
FDR[j] = V[j]/R[j]
}
plot(R, FDR, xlab="Number of Rejections", type="l", ylab="False Discovery Rate", col=4, lwd=3)
oo = order(abs(T))
R[oo] = R		# ordering을 하지 않으면 index가 뒤죽박죽
FDR[oo] = FDR
alpha = 0.1
max(R[FDR <= alpha])
sort(index[FDR <= alpha])
pval = NULL
for (j in 1:m){
k = index[j]
pval[j] = t.test(x1[, k], x2[, k], var.equal=TRUE)$p.value
}
# Computation of Plug-in FDR
m = 200
B = 1000	# 시간관계상 1000번이지, 실제로는 매우 적은 횟수
set.seed(111)
index = sample(2308, m)
T = rep(NA, m)
T.star = matrix(NA, nrow=m, ncol=B)
for (j in 1:m){
k = index[j]
T[j] = t.test(x1[, k], x2[, k], var.equal=TRUE)$statistic
for (b in 1:B) {
dat = sample(c(x1[, k], x2[, k]))
T.star[j, b] = t.test(dat[1:n1], dat[(n1 + n1) : (n1 + n2)], var.equal=TRUE)$statistic
}
}
c = sort(abs(T))
FDR = R = V = rep(NA, m)
for (j in 1:m){
R[j] = sum(abs(T) >= c[j])
V[j] = sum(abs(T.star) >= c[j])/B
FDR[j] = V[j]/R[j]
}
plot(R, FDR, xlab="Number of Rejections", type="l", ylab="False Discovery Rate", col=4, lwd=3)
oo = order(abs(T))
R[oo] = R		# ordering을 하지 않으면 index가 뒤죽박죽
FDR[oo] = FDR
alpha = 0.1
max(R[FDR <= alpha])
sort(index[FDR <= alpha])
pval = NULL
for (j in 1:m){
k = index[j]
pval[j] = t.test(x1[, k], x2[, k], var.equal=TRUE)$p.value
}
pBH = p.adjust(pval, method="BH")
data.frame(Resampling=round(FDR ,6), BH=round(pBH, 6))	# Resampling과 Benjamini procedure의 값이 거의 비슷함을 알 수 있음
oo = order(pBH)
plot(FDR[oo], pBH[oo], pch=20, xlab="Reampling FDR", ylab="BH procedure")
abline(0, 1, col="red", lty=2)	# 시각화 결과 y=x선상에 거의 겹침, 즉 값이 거의 일치
R
T.star
dim(T.star)
c
dim(sort)
dim(c)
legnth(c)
length(c)
abs(T.star)
# Least Square Estimation
data(golub, package="multtest")
zyxin = grep("Zyxin", golub.gnames[,2], ignore.case=TRUE)
cmyb = grep("c-myb", golub.gnames[,2], ignore.case=TRUE)
x = golub[zyxin, ]
y = golub[cmyb, ]
leastSquares = lm(y ~ x)
leastSquares$coef
plot(x, y, pch=19, xlab="Relative zyxin gene expression", ylab="Relative c-MYB gene expression", cex.lab=1.5, col="blue")
abline(leastSquares$coef, lwd=3, lty=2, col="red")
lmSummary = summary(leastSquares)
lmSummary
dim(x)
length(x)
# Linear Model with a Factor
y = c(2, 3, 1, 2, 8, 7, 9, 8, 11, 12, 13, 12)
factor = gl(3, 4) # gl : Generate factors by specifying the pattern of their levels.
factor
model.matrix(y ~ factor - 1)  # model.matrix = design matrix X, -1 indicates model has no intercept
summary(lm(y ~ factor -1))  # p-values are too small -> Reject H0 (mu_j = 0)
length(y)
summary(lm(y ~ factor -1))  # p-values are too small -> Reject H0 (mu_j = 0)
# Linear Model in ANOVA
set.seed(123)
y = c(rnorm(10, -1, 1), rnorm(10, 0, 1), rnorm(10, 1, 1))
y
factor = gl(3, 10)
factor
model.matrix(y ~ factor -1)
model.matrix(y ~ factor)  # Reference : factor1
g1 = lm(y ~ factor -1)
g2 = lm(y ~ factor)
summary(g1)$coef  # we can see mean of reference equals to estimates of intercept
summary(g2)$coef
anova(g1) # Wrong result (because of df=3)
anova(g2)
y = c(2, 3, 1, 2, 8, 7, 9, 8, 11, 12, 13, 12)
factor = gl(3, 4)
groupMeans = as.numeric(tapply(y, factor, mean))  # tapply : perform function about factor
groupMeans
mean(y)
g = 3
n = 4
N = 12
g = 3
n = 4
N = 12
ssb = 0
for (j in 1:g) {
ssb = ssb + (groupMeans[j] - mean(y))^2
}
SSB = n * ssb
SSB
SSW = 0
for (j in 1:g) {
SSW = SSW + sum((y[factor==j] - groupMeans[j])^2)
}
f.value = (SSB/(g-1)) / (SSW/(N-g))
f.value
pf(f.value, g-1, N-g, lower.tail=FALSE) # lower.tail : calculate only tail
g = lm(y ~ factor)
anova(g)
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("golubEsets")
library(golubEsets)
library(rpart)
library(e1071)
source("~/.active-rstudio-document", echo=TRUE)
install.packages("rpart")
install.packages("e1071")
data(golubEsest)
data(golubMerge)
data = data(golubMerge)
data
list(data)
dim(data)
data
data = data(Golub_Merge)
data
dim(data)
data(golubMerge)
data(Golub_Merge)
data
data = data(Golub_Merge)
data
x = data(Golub_Merge)
x
data(golubTest)
BiocManager::install("golubEsets")
x = data(Golub_Merge)
x
x = data(Golub_Merge)$Golub_Merge
library(golubEsets)
x = data(Golub_Merge)
x
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("golubEsets")
library(golubEsets)
library(rpart)
library(e1071)
x = data(Golub_Merge)
x
library(SubLasso)
install.packages("golubEsets")
install.packages("golubEsets")
library(golubEsets)
x = data(Golub_Merge)
x
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("golubEsets")
library(golubEsets)
data("Golub_Merge")
x = data("Golub_Merge")
x
data(Golub_Merge)
rm(list=ls())
data(Golub_Merge)
View(Golub_Merge)
Golub_Merge$ALL.AML
exprs(Golub_Merge)
data = exprs(Golub_Merge)
data
dim(data)
colnames(data)
golub$ALL.AML
Golub_Merge$ALL.AML
fac = Golub_Merge$ALL.AML
fac
Golub_Merge
exprs(Golub_Merge)
data
colnames(data)
fac
str(Golub_Merge)
golub.cl
path = '/Users/imdohyeon/Desktop/3-1/Multivariate_Analysis_1/rmtda/trackrecord2005-men.txt'
# sol1)
data = read.table(path)
data
# sol1)
data = read.table(path, header=T)
data
X = data
# sol1)
pca = princomp(X, cor=T)
pca.scores = pca$scores
pca.scores
# euclidean distance
de = as.matrix(dist(pca.scores, method="euclidean"))
de = as.dist(de)
round(de, 3)
pca.scores[1,2]
pca.scores[,1:2]
### sol1)
# pca scores
pca = princomp(X, cor=T)
pca.scores = pca$scores[, 1:2]
pca.scores
# euclidean distance
de = as.matrix(dist(pca.scores, method="euclidean"))
de = as.dist(de)
round(de, 3)
### sol2)
sinlge = hclust(de, method="single")
complete = hclust(de, method="complete")
ward = hclust(de, method="ward")
### sol2)
sinlge = hclust(de, method="single")
complete = hclust(de, method="complete")
ward = hclust(de, method="ward.D")
par(mfrow=c(1,3))
plot(single, main="Single linkage")
plot(complete, main="Complete linkage")
plot(ward, main="Ward linkage")
plot(single, main="Single linkage")
### sol2)
single = hclust(de, method="single")
complete = hclust(de, method="complete")
ward = hclust(de, method="ward.D")
par(mfrow=c(1,3))
plot(single, main="Single linkage")
plot(complete, main="Complete linkage")
plot(ward, main="Ward linkage")
par(mfrow=c(1,1))
plot(single, main="Single linkage")
rect.hclust(single, h=3)
plot(complete, main="Complete linkage")
plot(single, main="Single linkage")
rect.hclust(single, k=2)
plot(complete, main="Complete linkage")
rect.hclust(complete, k=3)
plot(ward, main="Ward linkage")
rect.hclust(ward, k=3)
### sol3)
library(NbClust)
k = NbClust(pca.scores, distance="euclidean",min.nc=2,max.nc=8,method="kmeans",index="all")
kmeans = kmeans(pac.scores, k) # we choose k=4
kmeans = kmeans(pca.scores, k) # we choose k=4
kmeans = kmeans(pca.scores, 3) # we choose k=3
cluster = data.frame(rownaems(X), cluster=kmeans$cluster)
cluster = data.frame(rownames(X), cluster=kmeans$cluster)
cluster
cluster = data.frame(cluster=kmeans$cluster)
cluster
kmeans$cluster
kmeans = kmeans(pca.scores, 3) # we choose k=3
cluster = data.frame(cluster=kmeans$cluster)
cluster
### sol4)
# Euclidean distance
origin.k = NbClust(X, distance="euclidean")
### sol4)
# Euclidean distance
origin.k = NbClust(X, distance="euclidean", method="kmeans", index="all")
### sol4)
# Euclidean distance
origin.k = NbClust(X, distance="euclidean",min.nc=2,max.nc=8,method="kmeans",index="all")
# Stnadardized euclidean distance
Z = scale(X, scale=T)
stand.k = NbClust(Z, distance="euclidean",min.nc=2,max.nc=8,method="kmeans",index="all")
plot(X)
kmeans = kmeans(X, 4) # We choose K=4
kmeans = kmeans(pca.scores, 3) # We choose K=3
cluster = data.frame(cluster=kmeans$cluster)
cluster
origin.kmeans = kmeans(X, 4) # We choose K=4
origin.cluster = data.frame(cluster=origin.k$cluster)
origin.cluster
origin.cluster = data.frame(cluster=origin.kmeans$cluster)
origin.cluster
stand.kmeans = kmeans(Z, 4) # We choose K=4
stand.cluster = data.frame(cluster=stand.kmeans$cluster)
stand.cluster
stand.clusters = data.frame(pca.cluster=kmeans$cluster, origin.cluster=stand.kmeans$cluster)
stand.clusters
origin.clusters
origin.clusters = data.frame(pca.cluster=kmeans$cluster, origin.cluster=origin.kmeans$cluster)
origin.clusters
hclust.kmeans.cluster = data.frame(
single=cutree(single, k=2), complete=cutree(complete, 3), ward=cutree(ward, 3),
kmeans=kmeans$cluster
)
hclust.kmeans.cluster
hclust.kmeans.clusters = data.frame(
single=cutree(single, k=2), complete=cutree(complete, 3), ward=cutree(ward, 3),
kmeans=kmeans$cluster
)
hclust.kmeans.clusters
pca.scores
pca.scores
# euclidean distance
de = as.matrix(dist(pca.scores, method="euclidean"))
de = as.dist(de)
round(de, 3)
round(de, 3)
round(de, 3)
# euclidean distance
de = as.matrix(dist(pca.scores, method="euclidean"))
de = as.dist(de)
round(de, 3)
# single-linkage method
plot(single, main="Single linkage")
rect.hclust(single, k=2)
# single-linkage method
plot(single, main="Single linkage")
rect.hclust(single, k=2)
dev.off()
# single-linkage method
plot(single, main="Single linkage")
rect.hclust(single, k=2)
# complete-linkage method
plot(complete, main="Complete linkage")
rect.hclust(complete, k=3)
# ward-linkage method
plot(ward, main="Ward linkage")
rect.hclust(ward, k=3)
dim(X)
# cluster means
single.agg = aggregate(X, by=list(cutree(single)))
# cluster means
single.agg = aggregate(X, by=list(cutree(single)), means)
# cluster means
single.agg = aggregate(X, by=list(cutree(single)), FUN=mean)
# cluster means
single.agg = aggregate(X, by=list(cutree(single), 2), FUN=mean)
# cluster means
single.agg = aggregate(X, by=list(cutree(single), k=2), FUN=mean)
# cluster means
single.agg = aggregate(X, by=list(cutree(single), k=2), FUN=mean)
# cluster means
single.agg = aggregate(X, by=list(cutree(single, k=2)), FUN=mean)
single.agg
complete.agg = aggregate(X, by=list(cutree(complete, k=3)), FUN=mean)
complete.agg
ward.agg = aggregate(X, by=list(cutree(ward, k=3)), FUN=mean)
ward.agg
# cluster means
single.agg = aggregate(X, by=list(cutree(single, k=2)), FUN=mean)
complete.agg = aggregate(X, by=list(cutree(complete, k=3)), FUN=mean)
sinlge.agg
complete.agg
# cluster means
single.agg = aggregate(X, by=list(cutree(single, k=2)), FUN=mean)
complete.agg = aggregate(X, by=list(cutree(complete, k=3)), FUN=mean)
single.agg
complete.agg
single.agg ; complete.agg
# single vs complete
par(mfrow=c(1,2))
plot(single, main="Single linkage")
plot(complete, main="Complete linkage")
# single vs complete
par(mfrow=c(1,2))
plot(single, main="Single linkage")
rect.hclust(single, k=2)
plot(complete, main="Complete linkage")
rect.hclust(complete, k=3)
### sol4)
# Euclidean distance
origin.k = NbClust(X, distance="euclidean",min.nc=2,max.nc=8,method="kmeans",index="all")
# cluster means
sinlge.result = cutree(single, k=2)
complete.result = cutree(complete, k=3)
# cluster means
single.result = cutree(single, k=2)
complete.result = cutree(complete, k=3)
single.result ; complete.result
single.result
single.result
complete.result
single.agg
complete.agg
### sol3)
# Choose number of Clusters : K
library(NbClust)
k = NbClust(pca.scores, distance="euclidean",min.nc=2,max.nc=8,method="kmeans",index="all")
kmeans = kmeans(pca.scores, 3) # We choose K=3
kmeans$cluster
hclust.kmeans.clusters = data.frame(
single=cutree(single, k=2), complete=cutree(complete, 3),
kmeans=kmeans$cluster
)
hclust.kmeans.clusters
### sol4)
# Euclidean distance
origin.k = NbClust(X, distance="euclidean",min.nc=2,max.nc=8,method="kmeans",index="all")
kmeans = kmeans(pca.scores, 3) # We choose K=3
kmeans$cluster
kmeans = kmeans(pca.scores, 3) # We choose K=3
hclust.kmeans.clusters = data.frame(
single=cutree(single, k=2), complete=cutree(complete, 3),
kmeans=kmeans$cluster
)
hclust.kmeans.clusters
condition= (hclust.kmeans.clusters[, "complete"] != hclust.kmeans.clusters[, "kmeans"])
hclust.kmeans.clusters[condition]
hclust.kmeans.clusters[condition, ]
kmeans$cluster
kmeans$cluster
hclust.kmeans.clusters[condition, ]
kmeans.agg = aggregate(X, by=list(cutree(kmeans, k=3)), FUN=mean)
single.agg = aggregate(X, by=list(cutree(kmeans, k=3)), FUN=mean)
single.agg = aggregate(X, by=list(cutree(kmeans$cluster, k=3)), FUN=mean)
single.agg = aggregate(X, by=list(kmeans$cluster), FUN=mean)
kmeans.agg = aggregate(X, by=list(kmeans$cluster), FUN=mean)
kmeans.agg
kmeans.agg = aggregate(X, by=list(kmeans$cluster), FUN=mean)
kmeans.agg
### sol4)
# Euclidean distance
origin.k = NbClust(X, distance="euclidean",min.nc=2,max.nc=8,method="kmeans",index="all")
### sol4)
# Euclidean distance
origin.k = NbClust(X, distance="euclidean",min.nc=2,max.nc=8,method="kmeans",index="all")
origin.kmeans = kmeans(X, 4) # We choose K=4
origin.clusters = data.frame(pca.cluster=kmeans$cluster, origin.cluster=origin.kmeans$cluster)
origin.clusters
aggregate(X, by=list(origin.kmeans$cluster), FUN=mean)
kmeans.agg
aggregate(X, by=list(origin.kmeans$cluster), FUN=mean)
origin.agg = aggregate(X, by=list(origin.kmeans$cluster), FUN=mean)
origin.agg
origin.kmeans$cluster
origin.kmeans$cluster != stand.kmeans$cluster
origin.kmeans$cluster
stand.kmeans$cluster
aggregate(X, by=list(stand.kmeans$cluster), FUN=mean)
plot(X, labels=kmeans$cluster)
plot(X[,1], labels=kmeans$cluster)
plot(X[,"x100"], X[,"Marathon"], labels=kmeans$cluster)
par(mfrow=c(1,1))
plot(X[,"x100"], X[,"Marathon"], labels=kmeans$cluster)
par(mfrow=c(1,1))
par(mfrow=c(1,1))
par(mfrow=c(1,1))
plot(X[,"x100"], X[,"Marathon"])
plot(X[,"x100"], X[,"Marathon"], xlab="100m", ylab="marathon")
plot(X[,"x100"], X[,"Marathon"], xlab="100m", ylab="marathon", main="kmeans-pca.scores", col=kmeans$cluster)
plot(X[,"x100"], X[,"Marathon"], xlab="100m", ylab="marathon", main="kmeans-pca.scores", col=kmeans$cluster, pch=16)
plot(X[,"x100"], X[,"Marathon"], xlab="100m", ylab="marathon", main="kmeans-originin", col=kmeans$cluster, pch=16)
par(mfrow=c(1,2))
plot(X[,"x100"], X[,"Marathon"], xlab="100m", ylab="marathon", main="kmeans-pca.scores", col=kmeans$cluster, pch=16)
plot(X[,"x100"], X[,"Marathon"], xlab="100m", ylab="marathon", main="kmeans-originin", col=kmeans$cluster, pch=16)
par(mfrow=c(1,2))
plot(X[,"x100"], X[,"Marathon"], xlab="100m", ylab="marathon", main="kmeans-pca.scores", col=kmeans$cluster, pch=16)
plot(X[,"x100"], X[,"Marathon"], xlab="100m", ylab="marathon", main="kmeans-originin", col=origin.kmeans$cluster, pch=16)
plot(X[,"x100"], X[,"Marathon"], xlab="100m", ylab="marathon", main="kmeans-originin", col=stand.kmeans$cluster, pch=16)
plot(X[,"x100"], X[,"Marathon"], xlab="100m", ylab="marathon", main="kmeans-pca.scores", col=kmeans$cluster, pch=16)
plot(X[,"x100"], X[,"Marathon"], xlab="100m", ylab="marathon", main="kmeans-originin", col=stand.kmeans$cluster, pch=16)
par(mfrow=c(1,2))
plot(X[,"x100"], X[,"Marathon"], xlab="100m", ylab="marathon", main="kmeans-pca.scores", col=kmeans$cluster, pch=16)
plot(X[,"x100"], X[,"Marathon"], xlab="100m", ylab="marathon", main="kmeans-originin", col=stand.kmeans$cluster, pch=16)
par(mfrow=c(1,2))
plot(X[,"x100"], X[,"Marathon"], xlab="100m", ylab="marathon", main="kmeans-pca.scores", col=kmeans$cluster, pch=16)
plot(X[,"x100"], X[,"Marathon"], xlab="100m", ylab="marathon", main="kmeans-origin", col=origin.kmeans$cluster, pch=16)
par(mfrow=c(1,2))
plot(X[,"x100"], X[,"Marathon"], xlab="100m", ylab="marathon", main="kmeans-pca.scores", col=kmeans$cluster, pch=16)
plot(X[,"x100"], X[,"Marathon"], xlab="100m", ylab="marathon", main="kmeans-origin", col=origin.kmeans$cluster, pch=16)
par(mfrow=c(1,2))
plot(X[,"x100"], X[,"Marathon"], xlab="100m", ylab="marathon", main="kmeans-pca.scores", col=kmeans$cluster, pch=16)
plot(X[,"x100"], X[,"Marathon"], xlab="100m", ylab="marathon", main="kmeans-origin", col=origin.kmeans$cluster, pch=16)
stand.k = NbClust(Z, distance="euclidean",min.nc=2,max.nc=8,method="kmeans",index="all")
stand.kmeans = kmeans(Z, 4) # We choose K=4
stand.kmeans$cluster
stand.agg = aggregate(X, by=list(stand.kmeans$cluster), FUN=mean)
stand.agg
stand.kmeans = kmeans(Z, 4) # We choose K=4
stand.kmeans$cluster
stand.agg = aggregate(X, by=list(stand.kmeans$cluster), FUN=mean)
stand.agg
origin.kmeans = kmeans(X, 4) # We choose K=4
origin.kmeans$cluster
origin.agg = aggregate(X, by=list(origin.kmeans$cluster), FUN=mean)
origin.agg
par(mfrow=c(1,2))
plot(X[,"x100"], X[,"Marathon"], xlab="100m", ylab="marathon", main="kmeans-pca.scores", col=kmeans$cluster, pch=16)
plot(X[,"x100"], X[,"Marathon"], xlab="100m", ylab="marathon", main="kmeans-origin", col=stand.kmeans$cluster, pch=16)
par(mfrow=c(1,2))
plot(X[,"x100"], X[,"Marathon"], xlab="100m", ylab="marathon", main="kmeans-pca.scores", col=kmeans$cluster, pch=16)
plot(X[,"x100"], X[,"Marathon"], xlab="100m", ylab="marathon", main="kmeans-standardized", col=stand.kmeans$cluster, pch=16)
